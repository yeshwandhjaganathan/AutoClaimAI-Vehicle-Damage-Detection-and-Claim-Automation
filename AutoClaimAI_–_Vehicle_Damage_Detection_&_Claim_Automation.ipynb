{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxB3AC9lt7HQAt1wIPwHOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeshwandhjaganathan/AutoClaimAI-Vehicle-Damage-Detection-and-Claim-Automation/blob/main/AutoClaimAI_%E2%80%93_Vehicle_Damage_Detection_%26_Claim_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z69DmBHlAbsL"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision ultralytics tensorflow pillow numpy imagehash shap opencv-python-headless matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import numpy as np\n",
        "import imagehash\n",
        "import shap\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "print(\"tensorflow:\", tf.__version__)\n",
        "print(\"PIL:\", PIL.__version__)\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"imagehash:\", imagehash.__version__)\n",
        "print(\"shap:\", shap.__version__)\n",
        "print(\"opencv:\", cv2.__version__)\n",
        "\n",
        "print(\"‚úÖ All libraries loaded successfully!\")"
      ],
      "metadata": {
        "id": "qP1vvkHqBugY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading YOLOv5 model...\")\n",
        "yolo_model = YOLO('yolov5s.pt')\n",
        "print(\"‚úÖ YOLOv5s model loaded!\")"
      ],
      "metadata": {
        "id": "Tp0YGs45CAsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "NUM_SEVERITY_CLASSES = 3  # Minor, Moderate, Severe\n",
        "\n",
        "def create_densenet_model(num_classes, input_shape=(224,224,3)):\n",
        "    base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation=\"relu\")(x)\n",
        "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"Creating DenseNet model...\")\n",
        "densenet_model = create_densenet_model(NUM_SEVERITY_CLASSES)\n",
        "densenet_model.summary()\n",
        "print(\"‚úÖ DenseNet model ready (ImageNet weights).\")"
      ],
      "metadata": {
        "id": "AACLiWdpCPAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Upload files (images/videos)\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "uploaded_image_paths = []\n",
        "\n",
        "# Directory to save extracted frames\n",
        "frames_dir = \"video_frames\"\n",
        "os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "for filename in uploaded_files.keys():\n",
        "    extension = filename.split(\".\")[-1].lower()\n",
        "\n",
        "    if extension in [\"jpg\", \"jpeg\", \"png\"]:\n",
        "        # Image file: Save as-is\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(uploaded_files[filename])\n",
        "        uploaded_image_paths.append(filename)\n",
        "        print(f\"‚úÖ Image uploaded: {filename}\")\n",
        "\n",
        "    elif extension in [\"mp4\", \"avi\", \"mov\", \"mkv\"]:\n",
        "        # Video file: Extract frames\n",
        "        video_path = filename\n",
        "        with open(video_path, 'wb') as f:\n",
        "            f.write(uploaded_files[filename])\n",
        "        print(f\"üé• Video uploaded: {filename}\")\n",
        "\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_interval = int(fps)  # 1 frame per second\n",
        "\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        frame_count = 0\n",
        "\n",
        "        while success:\n",
        "            if count % frame_interval == 0:\n",
        "                frame_filename = os.path.join(frames_dir, f\"{filename}_frame_{frame_count}.jpg\")\n",
        "                cv2.imwrite(frame_filename, image)\n",
        "                uploaded_image_paths.append(frame_filename)\n",
        "                print(f\"üñºÔ∏è Extracted frame: {frame_filename}\")\n",
        "                frame_count += 1\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "\n",
        "        vidcap.release()\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Unsupported file type: {filename}\")\n",
        "\n",
        "if uploaded_image_paths:\n",
        "    print(\"\\n‚úÖ All files processed. List of images/frames to analyze:\")\n",
        "    for path in uploaded_image_paths:\n",
        "        print(f\"- {path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid images or video frames uploaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "rLENCB_7DP_K",
        "outputId": "ee4efcbb-f79f-49e2-b171-15468ec8d5cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-2913895868.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Upload files (images/videos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0muploaded_image_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detected_images_info = []\n",
        "\n",
        "for image_path in uploaded_image_paths:\n",
        "    print(\"\\nProcessing:\", image_path)\n",
        "    results = yolo_model(image_path)\n",
        "    for r in results:\n",
        "        im_array = r.plot()\n",
        "        im_rgb = PIL.Image.fromarray(im_array[...,::-1])\n",
        "        plt.figure(figsize=(8,6))\n",
        "        plt.imshow(im_rgb)\n",
        "        plt.title(\"YOLOv5 Detection\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        detected_objects = []\n",
        "        for box in r.boxes:\n",
        "            x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
        "            conf = float(box.conf[0])\n",
        "            cls = int(box.cls[0])\n",
        "            class_name = yolo_model.names[cls]\n",
        "            detected_objects.append({\n",
        "                \"box\": [x1,y1,x2,y2],\n",
        "                \"confidence\": conf,\n",
        "                \"class_name\": class_name\n",
        "            })\n",
        "\n",
        "        detected_images_info.append({\n",
        "            \"image_path\": image_path,\n",
        "            \"detections\": detected_objects\n",
        "        })"
      ],
      "metadata": {
        "id": "PXqznBh_DW2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEVERITY_LABELS = [\"Minor\", \"Moderate\", \"Severe\"]\n",
        "\n",
        "classified_images_info = []\n",
        "\n",
        "for img_info in detected_images_info:\n",
        "    img_path = img_info[\"image_path\"]\n",
        "    img = PIL.Image.open(img_path).convert(\"RGB\")\n",
        "    img_resized = img.resize((224,224))\n",
        "    img_array = np.array(img_resized) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = densenet_model.predict(img_array)\n",
        "    idx = np.argmax(pred[0])\n",
        "    conf = pred[0][idx]\n",
        "\n",
        "    print(f\"\\nImage: {os.path.basename(img_path)} - Severity: {SEVERITY_LABELS[idx]} ({conf*100:.2f}%)\")\n",
        "\n",
        "    classified_images_info.append({\n",
        "        \"image_path\": img_path,\n",
        "        \"predicted_severity\": SEVERITY_LABELS[idx],\n",
        "        \"confidence\": conf,\n",
        "        \"predicted_class_idx\": idx\n",
        "    })"
      ],
      "metadata": {
        "id": "baHT0VRkDt4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "stored_claim_hashes = []  # Simulated previous hashes\n",
        "\n",
        "def check_duplicate(image_path, stored_hashes, threshold=5):\n",
        "    img = Image.open(image_path).convert(\"L\")\n",
        "    current_hash = imagehash.average_hash(img)\n",
        "    for h in stored_hashes:\n",
        "        if abs(current_hash - h) <= threshold:\n",
        "            return True, str(h)\n",
        "    return False, None\n",
        "\n",
        "fraud_check_results = []\n",
        "\n",
        "for img_path in uploaded_image_paths:\n",
        "    is_dup, hash_match = check_duplicate(img_path, stored_claim_hashes)\n",
        "    print(f\"\\nImage: {os.path.basename(img_path)} - Duplicate: {'Yes' if is_dup else 'No'}\")\n",
        "    fraud_check_results.append({\n",
        "        \"image_path\": img_path,\n",
        "        \"is_duplicate\": is_dup,\n",
        "        \"matching_hash\": hash_match if hash_match else \"None\"\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyKu9dBRD8fz",
        "outputId": "8e68c698-cf35-497f-85c0-621612886246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image: images (15).jpeg - Duplicate: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================= FINAL REPORT =================\")\n",
        "for img_info in classified_images_info:\n",
        "    img_path = img_info[\"image_path\"]\n",
        "    img_name = os.path.basename(img_path)\n",
        "    severity = img_info[\"predicted_severity\"]\n",
        "    conf_pct = img_info[\"confidence\"] * 100\n",
        "\n",
        "    detection_info = next((d for d in detected_images_info if d[\"image_path\"]==img_path), None)\n",
        "    fraud_info = next((f for f in fraud_check_results if f[\"image_path\"]==img_path), None)\n",
        "\n",
        "    print(f\"\\nImage: {img_name}\")\n",
        "    print(\"- Damage Detection:\")\n",
        "    if detection_info and detection_info[\"detections\"]:\n",
        "        classes = [d[\"class_name\"] for d in detection_info[\"detections\"]]\n",
        "        confidences = [f\"{d['confidence']*100:.2f}%\" for d in detection_info[\"detections\"]]\n",
        "        boxes = [d[\"box\"] for d in detection_info[\"detections\"]]\n",
        "        print(f\"    Objects Detected: {', '.join(classes)}\")\n",
        "        print(f\"    Confidence: {confidences}\")\n",
        "        print(f\"    Bounding Boxes: {boxes}\")\n",
        "    else:\n",
        "        print(\"    No objects detected.\")\n",
        "\n",
        "    print(\"- Severity Classification:\")\n",
        "    print(f\"    Predicted Severity: {severity}\")\n",
        "    print(f\"    Confidence: {conf_pct:.2f}%\")\n",
        "\n",
        "    print(\"- Fraud Check:\")\n",
        "    status = \"Unique\"\n",
        "    if fraud_info and fraud_info[\"is_duplicate\"]:\n",
        "        status = f\"Duplicate (Matched Hash: {fraud_info['matching_hash']})\"\n",
        "    print(f\"    Status: {status}\")\n",
        "\n",
        "print(\"\\n================= END OF REPORT =================\")"
      ],
      "metadata": {
        "id": "jQW3FfiTECcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "final_data = []\n",
        "\n",
        "for img_info in classified_images_info:\n",
        "    img_path = img_info[\"image_path\"]\n",
        "    img_name = os.path.basename(img_path)\n",
        "    severity = img_info[\"predicted_severity\"]\n",
        "    severity_conf = round(img_info[\"confidence\"] * 100, 2)\n",
        "\n",
        "    detection_info = next((d for d in detected_images_info if d[\"image_path\"]==img_path), None)\n",
        "    fraud_info = next((f for f in fraud_check_results if f[\"image_path\"]==img_path), None)\n",
        "\n",
        "    if detection_info and detection_info[\"detections\"]:\n",
        "        detected_classes = ', '.join([d[\"class_name\"] for d in detection_info[\"detections\"]])\n",
        "        detected_confs = ', '.join([f\"{d['confidence']*100:.2f}%\" for d in detection_info[\"detections\"]])\n",
        "        detected_boxes = str([d[\"box\"] for d in detection_info[\"detections\"]])\n",
        "    else:\n",
        "        detected_classes = \"None\"\n",
        "        detected_confs = \"None\"\n",
        "        detected_boxes = \"None\"\n",
        "\n",
        "    is_dup = \"Yes\" if fraud_info and fraud_info[\"is_duplicate\"] else \"No\"\n",
        "    hash_match = fraud_info[\"matching_hash\"] if fraud_info and fraud_info[\"is_duplicate\"] else \"N/A\"\n",
        "\n",
        "    final_data.append({\n",
        "        \"Image Name\": img_name,\n",
        "        \"Detected Objects\": detected_classes,\n",
        "        \"Detection Confidence\": detected_confs,\n",
        "        \"Bounding Boxes\": detected_boxes,\n",
        "        \"Predicted Severity\": severity,\n",
        "        \"Severity Confidence (%)\": severity_conf,\n",
        "        \"Duplicate Status\": is_dup,\n",
        "        \"Matched Hash\": hash_match\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(final_data)\n",
        "\n",
        "# Save to CSV\n",
        "csv_file_name = \"AutoClaimAI_Output_Report.csv\"\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "# Download link\n",
        "from google.colab import files\n",
        "files.download(csv_file_name)"
      ],
      "metadata": {
        "id": "myM59E8hEskV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}